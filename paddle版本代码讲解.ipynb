{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# PP复现RepVGG\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/652da8d77afb4614be737ef7e630af14f48f766682dd46baa11c208c42b995bf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 让vgg再一次伟大\n",
    "Hi guy！欢迎来到这里，这是对RepVGG代码的深入讲解，本notebook将逐行讲解代码，为什么要讲解呢，因为RepVGG的思想和工程意义吸引着大家，大简之道而不失性能，简单而又有效这是多么令人着迷！\n",
    "\n",
    "详细论文细节可以去github看我编写的md文件，这里不再阐述：\n",
    "\n",
    "如果对您有帮助，欢迎给个github star，希望你阅读快乐，每天基本都在，有问题可以及时反馈\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/92e22df6fcf44e7d99555daba4ab6bba82cdba4c47024d3fb16376692fe1cc7f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前版本为: 2.0.1\n"
     ]
    }
   ],
   "source": [
    "import paddle\r\n",
    "import numpy as np\r\n",
    "import paddle.nn as nn\r\n",
    "\r\n",
    "#国际惯例，导入所需要的包\r\n",
    "print('当前版本为:',paddle.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\r\n",
    "    result = paddle.nn.Sequential(\r\n",
    "        ('conv',nn.Conv2D(in_channels=in_channels, out_channels=out_channels,kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias_attr=False)),\r\n",
    "        ('bn',nn.BatchNorm2D(num_features=out_channels))\r\n",
    "    )\r\n",
    "    return result\r\n",
    "\r\n",
    "# 构造conv+bn组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#构建RepVGGBlock模块\r\n",
    "#RepVGG除了最后的池化层和分类层之外，都是清一色RepVGGBlock堆叠，十分简单\r\n",
    "\r\n",
    "class RepVGGBlock(nn.Layer):\r\n",
    "\r\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\r\n",
    "                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', deploy=False):\r\n",
    "        super(RepVGGBlock, self).__init__()\r\n",
    "        self.deploy = deploy             #deploy是推理部署的意思\r\n",
    "        self.groups = groups             #输入的特征层分为几组，这是分组卷积概念，单卡GPU不用考虑，默认为1，分组卷积概念详见下面\r\n",
    "        self.in_channels = in_channels   #输入通道\r\n",
    "\r\n",
    "        assert kernel_size == 3          #断言函数，RepVGG以 3x3 卷积闻名\r\n",
    "        assert padding == 1              #为什么这么设置呢，图像padding=1后经过 3x3 卷积之后图像大小不变\r\n",
    "        \r\n",
    "        padding_11 = padding - kernel_size // 2\r\n",
    "        \r\n",
    "        self.nonlinearity = nn.ReLU()\r\n",
    "\r\n",
    "\r\n",
    "        if deploy:\r\n",
    "            self.rbr_reparam = nn.Conv2D(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\r\n",
    "                                      padding=padding, dilation=dilation, groups=groups, bias_attr=True, padding_mode=padding_mode)\r\n",
    "        #定义推理模型时，基本block就是一个conv2D\r\n",
    "       \r\n",
    "\r\n",
    "\r\n",
    "        else:\r\n",
    "            self.rbr_identity = nn.BatchNorm2D(num_features=in_channels) if out_channels == in_channels and stride == 1 else None #直接连接，类似resnet残差连接，注意当输入通道和输出通道不同时候，\r\n",
    "                                                                                                                                  #只有 1x1 和 3x3 卷积，没有identity，下面网络图自己体会\r\n",
    "\r\n",
    "            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups) #3x3卷积+BN\r\n",
    "            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)          #1x1卷积+BN\r\n",
    "            print('RepVGG Block, identity = ', self.rbr_identity)   #这句话就是判断这个block没有identity，没有的话返回None，具体看下图输出\r\n",
    "        #定义训练模型时，基本block是identity, 1x1 conv_bn, 3x3 conv_bn组合\r\n",
    "\r\n",
    "\r\n",
    "    def forward(self, inputs):\r\n",
    "        if hasattr(self, 'rbr_reparam'):\r\n",
    "            return self.nonlinearity(self.rbr_reparam(inputs))\r\n",
    "        #推理阶段,conv2D后Relu\r\n",
    "\r\n",
    "        if self.rbr_identity is None:\r\n",
    "            id_out = 0\r\n",
    "        else:\r\n",
    "            id_out = self.rbr_identity(inputs)\r\n",
    "\r\n",
    "        return self.nonlinearity(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out)\r\n",
    "        #训练阶段，3x3,1x1,identity相加后Relu\r\n",
    "\r\n",
    "\r\n",
    "    def get_equivalent_kernel_bias(self):\r\n",
    "        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)   #卷积核两个参数W和b提出来\r\n",
    "        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\r\n",
    "        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)  #为啥可以提出两个参数，看论文公式\r\n",
    "        \r\n",
    "        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\r\n",
    "    #先理解_fuse_bn_tensor这个是干啥的，这模块就好理解了\r\n",
    "    #卷积核运算本质就是W(x)+b，但是为啥identity可以提取W，b?看后面\r\n",
    " \r\n",
    "\r\n",
    "    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\r\n",
    "        if kernel1x1 is None:\r\n",
    "            return 0\r\n",
    "        else:\r\n",
    "            return nn.functional.pad(kernel1x1, [1,1,1,1])\r\n",
    "    #这代码讲的是将1x1 conv padding一圈成3x3 conv, 填充的是0\r\n",
    "    #                     [0  0  0] \r\n",
    "    # [1]  >>>padding>>>  [0  1  0]\r\n",
    "    #                     [0  0  0]   \r\n",
    "\r\n",
    "\r\n",
    "    def _fuse_bn_tensor(self, branch):\r\n",
    "        if branch is None:\r\n",
    "            return 0, 0\r\n",
    "            #当branch不是3x3, 1x1, BN，那就返回W=0,b=0\r\n",
    "\r\n",
    "        if isinstance(branch, nn.Sequential):\r\n",
    "            kernel = branch.conv.weight            #conv权重\r\n",
    "            running_mean = branch.bn._mean  #BN mean\r\n",
    "            running_var = branch.bn._variance    #BN var\r\n",
    "            gamma = branch.bn.weight               #BN γ \r\n",
    "            beta = branch.bn.bias                  #BN β\r\n",
    "            eps = branch.bn._epsilon                    #防止分母为0\r\n",
    "            #当branch是3x3, 1x1时候，返回以上数据，为后面做融合\r\n",
    "\r\n",
    "        else:\r\n",
    "            assert isinstance(branch, nn.BatchNorm2D)\r\n",
    "            if not hasattr(self, 'id_tensor'):\r\n",
    "                input_dim = self.in_channels // self.groups                                       #通道分组，单个GPU不用考虑，详情去搜索分组卷积\r\n",
    "                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)    #定义新的3x3卷积核，参数为0，这里用到DepthWise，详情去搜索MobileNetV1\r\n",
    "                                                                                                  #这部分看后面讲解\r\n",
    "                for i in range(self.in_channels):\r\n",
    "                    kernel_value[i, i % input_dim, 1, 1] = 1                                      #将卷积核对角线部分赋予1\r\n",
    "                self.id_tensor = paddle.to_tensor(kernel_value)\r\n",
    "\r\n",
    "            kernel = self.id_tensor               #conv权重       \r\n",
    "            running_mean = branch._mean    #BN mean\r\n",
    "            running_var = branch._variance     #BN var\r\n",
    "            gamma = branch.weight                 #BN γ\r\n",
    "            beta = branch.bias                    #BN β\r\n",
    "            eps = branch._epsilon                      #防止分母为0\r\n",
    "            #当branch是identity，也即只有BN时候返回以上数据\r\n",
    "\r\n",
    "\r\n",
    "        std = (running_var + eps).sqrt()\r\n",
    "        t = (gamma / std).reshape((-1, 1, 1, 1))\r\n",
    "        #提取W，b，不管你是3x3 1x1 identity都要提取\r\n",
    "\r\n",
    "        return kernel * t, beta - running_mean * gamma / std\r\n",
    "        #细心的读者发现，上述公式没有提到conv（1x1,3x3）的bias\r\n",
    "        #这部分是精华，也是难以理解的部分，希望读者多多阅读代码，推推公式，深入理解原理\r\n",
    "\r\n",
    "\r\n",
    "    def repvgg_convert(self):\r\n",
    "        kernel, bias = self.get_equivalent_kernel_bias()\r\n",
    "        return kernel.numpy(), bias.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 疑惑部分讲解\n",
    "* `return kernel * t, beta - running_mean * gamma / std`这段代码是什么意思？\n",
    "   \n",
    "  ![](https://ai-studio-static-online.cdn.bcebos.com/75c1178f0b7644ee8415b5006618c06b7b95d2a899a64585b309c6d5b1b04144)\n",
    "   \n",
    "  官方代码里面不考虑训练模型的conv的bias，所以上面去掉b\n",
    "  \n",
    "* `kernel_value[i, i % input_dim, 1, 1] = 1`这段代码什么意思？\n",
    "  \n",
    "  首先我们看分组卷积\n",
    "  \n",
    "  ![](https://ai-studio-static-online.cdn.bcebos.com/72247e542a2b438fbaf5d6620ec3822309ddc1df91384685bf32a46048d7f9e8)\n",
    "  \n",
    "  对应这段代码`kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32) `，假设不分组单个GPU训练，group=1\n",
    "  我们看上图in_channels=input_dim=12,输出一个feature map需要的filter大小是（input_dim=12,3,3）\n",
    "  \n",
    "  但是in_channels怎么来的?我们思考一下上图左边的input如何经过3x3卷积输出identity效果，输出feature map数要和输入feature map数相同，所以filter数量必须是12，\n",
    "  所以总filter（12,12,3,3），那么新的问题来了，当input的12个feature map经过一个（12,3,3）生成一个feature map，如何跟原feature map其中一个相同。答案是将filter一个\n",
    "  channel设置1，其余全部为0\n",
    "  \n",
    "  ![](https://ai-studio-static-online.cdn.bcebos.com/7737623e74144fa5a12e0479c7c9d09d99d1d5e3f35948279d3205ae603e7133)\n",
    "  \n",
    "  ![](https://ai-studio-static-online.cdn.bcebos.com/01c621d136574cf6956bc43b690602ebd96e8ea54a284acea790cea980a9c9c5)\n",
    "  \n",
    "  如上图所示，当单个GPU时候，group=1，in_channel=input_dim=3,需要的filter大小是（in_channel=3,input_dim=3,H=3,w=3），我们发现卷积核中参数1分别在（0,0,1,1）（1,1,1,1）（2,2,1,1）刚好对应代码`kernel_value[i, i % input_dim, 1, 1] = 1`，如下图\n",
    "  \n",
    "  ![](https://ai-studio-static-online.cdn.bcebos.com/290c4795e7704cf8b7e812cbc3423b6db90e7f831906402aaa56a41247321e8e)\n",
    "  \n",
    "  要是还没看懂，评论区问，尽力解答\n",
    "  \n",
    "  论文原图如下，详细说明请看原论文或者上面的论文精读\n",
    "  \n",
    "  ![](https://ai-studio-static-online.cdn.bcebos.com/25ee65a3a1ab4f599a6ec73303bf12f34c0751251eea48d9a1f154e8ba5f662b)\n",
    "  \n",
    "* `self.rbr_identity = nn.BatchNorm2D(num_features=in_channels) if out_channels == in_channels and stride == 1 else None`\n",
    "\n",
    "  这是in_channel与out_channel不同时候的block，可以看出没有恒等连接\n",
    "\n",
    "  ![](https://ai-studio-static-online.cdn.bcebos.com/e896c3883ef64b6788bd1106fa9a5249234c03ee29834959b54f64dd05523d81)\n",
    "\n",
    "  这是in_channel与out_channel相同时候的block，可以看出有恒等连接\n",
    "\n",
    "  ![](https://ai-studio-static-online.cdn.bcebos.com/1148d68a9b114cd9885c813cd74dc638dc9e132b0aa647bf9fac9bc73a239af9)\n",
    "\n",
    "  当block负责对图像进行下采样，即stride=2时候，空间维度缩小，特征层增加，以此提取高层语义特征，这时候的block没有identity连接\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RepVGG(nn.Layer):\r\n",
    "\r\n",
    "    def __init__(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False):\r\n",
    "        super(RepVGG, self).__init__()\r\n",
    "\r\n",
    "        assert len(width_multiplier) == 4 #江湖人称瘦身因子，减小网络的宽度，就是输出通道乘以权重变小还是变大\r\n",
    "\r\n",
    "        self.deploy = deploy\r\n",
    "        self.override_groups_map = override_groups_map or dict() #这部分是分组卷积，单个GPU不用考虑\r\n",
    "\r\n",
    "        assert 0 not in self.override_groups_map\r\n",
    "\r\n",
    "        self.in_planes = min(64, int(64 * width_multiplier[0]))\r\n",
    "\r\n",
    "        self.stage0 = RepVGGBlock(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=2, padding=1, deploy=self.deploy)\r\n",
    "        self.cur_layer_idx = 1 #分组卷积\r\n",
    "        self.stage1 = self._make_stage(int(64 * width_multiplier[0]), num_blocks[0], stride=2)\r\n",
    "        self.stage2 = self._make_stage(int(128 * width_multiplier[1]), num_blocks[1], stride=2)\r\n",
    "        self.stage3 = self._make_stage(int(256 * width_multiplier[2]), num_blocks[2], stride=2)\r\n",
    "        self.stage4 = self._make_stage(int(512 * width_multiplier[3]), num_blocks[3], stride=2)\r\n",
    "        self.gap = nn.AdaptiveAvgPool2D(output_size=1)#全局池化，变成 Nx1x1（CxHxW） 类似flatten\r\n",
    "        self.linear = nn.Linear(int(512 * width_multiplier[3]), num_classes)\r\n",
    "        \r\n",
    "\r\n",
    "    def _make_stage(self, planes, num_blocks, stride):\r\n",
    "        strides = [stride] + [1]*(num_blocks-1)\r\n",
    "        blocks = []\r\n",
    "        for stride in strides:\r\n",
    "            cur_groups = self.override_groups_map.get(self.cur_layer_idx, 1)#分组卷积\r\n",
    "            blocks.append(RepVGGBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\r\n",
    "                                      stride=stride, padding=1, groups=cur_groups, deploy=self.deploy))\r\n",
    "            self.in_planes = planes\r\n",
    "            self.cur_layer_idx += 1\r\n",
    "        return nn.Sequential(*blocks)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        out = self.stage0(x)\r\n",
    "        out = self.stage1(out)\r\n",
    "        out = self.stage2(out)\r\n",
    "        out = self.stage3(out)\r\n",
    "        out = self.stage4(out)\r\n",
    "        out = self.gap(out)\r\n",
    "        out = paddle.flatten(out,start_axis=1)\r\n",
    "        out = self.linear(out)\r\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/a9431b0ef4d347e2b888a96213d6aea1b6797c768e544e0690aa9ffa2e06d602)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optional_groupwise_layers = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26]\r\n",
    "g2_map = {l: 2 for l in optional_groupwise_layers}\r\n",
    "g4_map = {l: 4 for l in optional_groupwise_layers}\r\n",
    "\r\n",
    "def create_RepVGG_A0(deploy=False,num_classes=10):\r\n",
    "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=num_classes,\r\n",
    "                  width_multiplier=[0.75, 0.75, 0.75, 2.5], override_groups_map=None, deploy=deploy)\r\n",
    "\r\n",
    "def create_RepVGG_A1(deploy=False,num_classes=10):\r\n",
    "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=num_classes,\r\n",
    "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\r\n",
    "\r\n",
    "def create_RepVGG_A2(deploy=False,num_classes=10):\r\n",
    "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=num_classes,\r\n",
    "                  width_multiplier=[1.5, 1.5, 1.5, 2.75], override_groups_map=None, deploy=deploy)\r\n",
    "\r\n",
    "\r\n",
    "def create_RepVGG_B0(deploy=False,num_classes=10):\r\n",
    "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=num_classes,\r\n",
    "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\r\n",
    "\r\n",
    "def create_RepVGG_B1(deploy=False,num_classes=10):\r\n",
    "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=num_classes,\r\n",
    "                  width_multiplier=[2, 2, 2, 4], override_groups_map=None, deploy=deploy)\r\n",
    "\r\n",
    "def create_RepVGG_B1g2(deploy=False,num_classes=10):\r\n",
    "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=num_classes,\r\n",
    "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g2_map, deploy=deploy)\r\n",
    "\r\n",
    "def create_RepVGG_B1g4(deploy=False,num_classes=10):\r\n",
    "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=num_classes,\r\n",
    "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g4_map, deploy=deploy)\r\n",
    "\r\n",
    "def create_RepVGG_B2(deploy=False,num_classes=10):\r\n",
    "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=num_classes,\r\n",
    "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=None, deploy=deploy)\r\n",
    "\r\n",
    "def create_RepVGG_B2g2(deploy=False,num_classes=10):\r\n",
    "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=num_classes,\r\n",
    "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g2_map, deploy=deploy)\r\n",
    "\r\n",
    "def create_RepVGG_B2g4(deploy=False,num_classes=10):\r\n",
    "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=num_classes,\r\n",
    "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g4_map, deploy=deploy)\r\n",
    "\r\n",
    "\r\n",
    "def create_RepVGG_B3(deploy=False,num_classes=10):\r\n",
    "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=num_classes,\r\n",
    "                  width_multiplier=[3, 3, 3, 5], override_groups_map=None, deploy=deploy)\r\n",
    "\r\n",
    "def create_RepVGG_B3g2(deploy=False,num_classes=10):\r\n",
    "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\r\n",
    "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g2_map, deploy=deploy)\r\n",
    "\r\n",
    "def create_RepVGG_B3g4(deploy=False,num_classes=10):\r\n",
    "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=num_classes,\r\n",
    "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g4_map, deploy=deploy)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/230ad30833984dbdbd518e0b95d4c89f0084152a08d04f84809c6bc7cfaca69e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RepVGG Block, identity =  None\n",
      "RepVGG Block, identity =  None\n",
      "RepVGG Block, identity =  BatchNorm2D(num_features=48, momentum=0.9, epsilon=1e-05)\n",
      "RepVGG Block, identity =  None\n",
      "RepVGG Block, identity =  BatchNorm2D(num_features=96, momentum=0.9, epsilon=1e-05)\n",
      "RepVGG Block, identity =  BatchNorm2D(num_features=96, momentum=0.9, epsilon=1e-05)\n",
      "RepVGG Block, identity =  BatchNorm2D(num_features=96, momentum=0.9, epsilon=1e-05)\n",
      "RepVGG Block, identity =  None\n",
      "RepVGG Block, identity =  BatchNorm2D(num_features=192, momentum=0.9, epsilon=1e-05)\n",
      "RepVGG Block, identity =  BatchNorm2D(num_features=192, momentum=0.9, epsilon=1e-05)\n",
      "RepVGG Block, identity =  BatchNorm2D(num_features=192, momentum=0.9, epsilon=1e-05)\n",
      "RepVGG Block, identity =  BatchNorm2D(num_features=192, momentum=0.9, epsilon=1e-05)\n",
      "RepVGG Block, identity =  BatchNorm2D(num_features=192, momentum=0.9, epsilon=1e-05)\n",
      "RepVGG Block, identity =  BatchNorm2D(num_features=192, momentum=0.9, epsilon=1e-05)\n",
      "RepVGG Block, identity =  BatchNorm2D(num_features=192, momentum=0.9, epsilon=1e-05)\n",
      "RepVGG Block, identity =  BatchNorm2D(num_features=192, momentum=0.9, epsilon=1e-05)\n",
      "RepVGG Block, identity =  BatchNorm2D(num_features=192, momentum=0.9, epsilon=1e-05)\n",
      "RepVGG Block, identity =  BatchNorm2D(num_features=192, momentum=0.9, epsilon=1e-05)\n",
      "RepVGG Block, identity =  BatchNorm2D(num_features=192, momentum=0.9, epsilon=1e-05)\n",
      "RepVGG Block, identity =  BatchNorm2D(num_features=192, momentum=0.9, epsilon=1e-05)\n",
      "RepVGG Block, identity =  BatchNorm2D(num_features=192, momentum=0.9, epsilon=1e-05)\n",
      "RepVGG Block, identity =  None\n"
     ]
    }
   ],
   "source": [
    "repvgg_a0=create_RepVGG_A0(num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### repvgg_a0 可视化\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/c7603f5214b4449e9f97a62db1f7d0c952e6f2124a7c44bda84e896e0c24c339)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cache file /home/aistudio/.cache/paddle/dataset/cifar/cifar-10-python.tar.gz not found, downloading https://dataset.bj.bcebos.com/cifar/cifar-10-python.tar.gz \n",
      "Begin to download\n",
      "\n",
      "Download finished\n"
     ]
    }
   ],
   "source": [
    "import paddle.vision.transforms as T\n",
    "from paddle.vision.datasets import Cifar10\n",
    "\n",
    "#数据准备\n",
    "transform = T.Compose([\n",
    "    T.Resize(size=(224,224)),\n",
    "    T.Normalize(mean=[127.5, 127.5, 127.5],std=[127.5, 127.5, 127.5],data_format='HWC'),\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = Cifar10(mode='train', transform=transform)\n",
    "val_dataset = Cifar10(mode='test',  transform=transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 高层API训练\n",
    "高层API灵活度不够，暂时没有想到办法通过高层API将train model转化成deploy model，不过大家可以训练一下看看acc如何，作为参考"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "   Layer (type)         Input Shape          Output Shape         Param #    \n",
      "===============================================================================\n",
      "     Conv2D-1        [[1, 3, 224, 224]]   [1, 48, 112, 112]        1,296     \n",
      "   BatchNorm2D-1    [[1, 48, 112, 112]]   [1, 48, 112, 112]         192      \n",
      "     Conv2D-2        [[1, 3, 224, 224]]   [1, 48, 112, 112]         144      \n",
      "   BatchNorm2D-2    [[1, 48, 112, 112]]   [1, 48, 112, 112]         192      \n",
      "      ReLU-1        [[1, 48, 112, 112]]   [1, 48, 112, 112]          0       \n",
      "   RepVGGBlock-1     [[1, 3, 224, 224]]   [1, 48, 112, 112]          0       \n",
      "     Conv2D-3       [[1, 48, 112, 112]]    [1, 48, 56, 56]        20,736     \n",
      "   BatchNorm2D-3     [[1, 48, 56, 56]]     [1, 48, 56, 56]          192      \n",
      "     Conv2D-4       [[1, 48, 112, 112]]    [1, 48, 56, 56]         2,304     \n",
      "   BatchNorm2D-4     [[1, 48, 56, 56]]     [1, 48, 56, 56]          192      \n",
      "      ReLU-2         [[1, 48, 56, 56]]     [1, 48, 56, 56]           0       \n",
      "   RepVGGBlock-2    [[1, 48, 112, 112]]    [1, 48, 56, 56]           0       \n",
      "   BatchNorm2D-5     [[1, 48, 56, 56]]     [1, 48, 56, 56]          192      \n",
      "     Conv2D-5        [[1, 48, 56, 56]]     [1, 48, 56, 56]        20,736     \n",
      "   BatchNorm2D-6     [[1, 48, 56, 56]]     [1, 48, 56, 56]          192      \n",
      "     Conv2D-6        [[1, 48, 56, 56]]     [1, 48, 56, 56]         2,304     \n",
      "   BatchNorm2D-7     [[1, 48, 56, 56]]     [1, 48, 56, 56]          192      \n",
      "      ReLU-3         [[1, 48, 56, 56]]     [1, 48, 56, 56]           0       \n",
      "   RepVGGBlock-3     [[1, 48, 56, 56]]     [1, 48, 56, 56]           0       \n",
      "     Conv2D-7        [[1, 48, 56, 56]]     [1, 96, 28, 28]        41,472     \n",
      "   BatchNorm2D-8     [[1, 96, 28, 28]]     [1, 96, 28, 28]          384      \n",
      "     Conv2D-8        [[1, 48, 56, 56]]     [1, 96, 28, 28]         4,608     \n",
      "   BatchNorm2D-9     [[1, 96, 28, 28]]     [1, 96, 28, 28]          384      \n",
      "      ReLU-4         [[1, 96, 28, 28]]     [1, 96, 28, 28]           0       \n",
      "   RepVGGBlock-4     [[1, 48, 56, 56]]     [1, 96, 28, 28]           0       \n",
      "  BatchNorm2D-10     [[1, 96, 28, 28]]     [1, 96, 28, 28]          384      \n",
      "     Conv2D-9        [[1, 96, 28, 28]]     [1, 96, 28, 28]        82,944     \n",
      "  BatchNorm2D-11     [[1, 96, 28, 28]]     [1, 96, 28, 28]          384      \n",
      "     Conv2D-10       [[1, 96, 28, 28]]     [1, 96, 28, 28]         9,216     \n",
      "  BatchNorm2D-12     [[1, 96, 28, 28]]     [1, 96, 28, 28]          384      \n",
      "      ReLU-5         [[1, 96, 28, 28]]     [1, 96, 28, 28]           0       \n",
      "   RepVGGBlock-5     [[1, 96, 28, 28]]     [1, 96, 28, 28]           0       \n",
      "  BatchNorm2D-13     [[1, 96, 28, 28]]     [1, 96, 28, 28]          384      \n",
      "     Conv2D-11       [[1, 96, 28, 28]]     [1, 96, 28, 28]        82,944     \n",
      "  BatchNorm2D-14     [[1, 96, 28, 28]]     [1, 96, 28, 28]          384      \n",
      "     Conv2D-12       [[1, 96, 28, 28]]     [1, 96, 28, 28]         9,216     \n",
      "  BatchNorm2D-15     [[1, 96, 28, 28]]     [1, 96, 28, 28]          384      \n",
      "      ReLU-6         [[1, 96, 28, 28]]     [1, 96, 28, 28]           0       \n",
      "   RepVGGBlock-6     [[1, 96, 28, 28]]     [1, 96, 28, 28]           0       \n",
      "  BatchNorm2D-16     [[1, 96, 28, 28]]     [1, 96, 28, 28]          384      \n",
      "     Conv2D-13       [[1, 96, 28, 28]]     [1, 96, 28, 28]        82,944     \n",
      "  BatchNorm2D-17     [[1, 96, 28, 28]]     [1, 96, 28, 28]          384      \n",
      "     Conv2D-14       [[1, 96, 28, 28]]     [1, 96, 28, 28]         9,216     \n",
      "  BatchNorm2D-18     [[1, 96, 28, 28]]     [1, 96, 28, 28]          384      \n",
      "      ReLU-7         [[1, 96, 28, 28]]     [1, 96, 28, 28]           0       \n",
      "   RepVGGBlock-7     [[1, 96, 28, 28]]     [1, 96, 28, 28]           0       \n",
      "     Conv2D-15       [[1, 96, 28, 28]]     [1, 192, 14, 14]       165,888    \n",
      "  BatchNorm2D-19     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "     Conv2D-16       [[1, 96, 28, 28]]     [1, 192, 14, 14]       18,432     \n",
      "  BatchNorm2D-20     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "      ReLU-8         [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "   RepVGGBlock-8     [[1, 96, 28, 28]]     [1, 192, 14, 14]          0       \n",
      "  BatchNorm2D-21     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "     Conv2D-17       [[1, 192, 14, 14]]    [1, 192, 14, 14]       331,776    \n",
      "  BatchNorm2D-22     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "     Conv2D-18       [[1, 192, 14, 14]]    [1, 192, 14, 14]       36,864     \n",
      "  BatchNorm2D-23     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "      ReLU-9         [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "   RepVGGBlock-9     [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  BatchNorm2D-24     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "     Conv2D-19       [[1, 192, 14, 14]]    [1, 192, 14, 14]       331,776    \n",
      "  BatchNorm2D-25     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "     Conv2D-20       [[1, 192, 14, 14]]    [1, 192, 14, 14]       36,864     \n",
      "  BatchNorm2D-26     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "      ReLU-10        [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  RepVGGBlock-10     [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  BatchNorm2D-27     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "     Conv2D-21       [[1, 192, 14, 14]]    [1, 192, 14, 14]       331,776    \n",
      "  BatchNorm2D-28     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "     Conv2D-22       [[1, 192, 14, 14]]    [1, 192, 14, 14]       36,864     \n",
      "  BatchNorm2D-29     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "      ReLU-11        [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  RepVGGBlock-11     [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  BatchNorm2D-30     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "     Conv2D-23       [[1, 192, 14, 14]]    [1, 192, 14, 14]       331,776    \n",
      "  BatchNorm2D-31     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "     Conv2D-24       [[1, 192, 14, 14]]    [1, 192, 14, 14]       36,864     \n",
      "  BatchNorm2D-32     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "      ReLU-12        [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  RepVGGBlock-12     [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  BatchNorm2D-33     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "     Conv2D-25       [[1, 192, 14, 14]]    [1, 192, 14, 14]       331,776    \n",
      "  BatchNorm2D-34     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "     Conv2D-26       [[1, 192, 14, 14]]    [1, 192, 14, 14]       36,864     \n",
      "  BatchNorm2D-35     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "      ReLU-13        [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  RepVGGBlock-13     [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  BatchNorm2D-36     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "     Conv2D-27       [[1, 192, 14, 14]]    [1, 192, 14, 14]       331,776    \n",
      "  BatchNorm2D-37     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "     Conv2D-28       [[1, 192, 14, 14]]    [1, 192, 14, 14]       36,864     \n",
      "  BatchNorm2D-38     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "      ReLU-14        [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  RepVGGBlock-14     [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  BatchNorm2D-39     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "     Conv2D-29       [[1, 192, 14, 14]]    [1, 192, 14, 14]       331,776    \n",
      "  BatchNorm2D-40     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "     Conv2D-30       [[1, 192, 14, 14]]    [1, 192, 14, 14]       36,864     \n",
      "  BatchNorm2D-41     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "      ReLU-15        [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  RepVGGBlock-15     [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  BatchNorm2D-42     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "     Conv2D-31       [[1, 192, 14, 14]]    [1, 192, 14, 14]       331,776    \n",
      "  BatchNorm2D-43     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "     Conv2D-32       [[1, 192, 14, 14]]    [1, 192, 14, 14]       36,864     \n",
      "  BatchNorm2D-44     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "      ReLU-16        [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  RepVGGBlock-16     [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  BatchNorm2D-45     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "     Conv2D-33       [[1, 192, 14, 14]]    [1, 192, 14, 14]       331,776    \n",
      "  BatchNorm2D-46     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "     Conv2D-34       [[1, 192, 14, 14]]    [1, 192, 14, 14]       36,864     \n",
      "  BatchNorm2D-47     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "      ReLU-17        [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  RepVGGBlock-17     [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  BatchNorm2D-48     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "     Conv2D-35       [[1, 192, 14, 14]]    [1, 192, 14, 14]       331,776    \n",
      "  BatchNorm2D-49     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "     Conv2D-36       [[1, 192, 14, 14]]    [1, 192, 14, 14]       36,864     \n",
      "  BatchNorm2D-50     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "      ReLU-18        [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  RepVGGBlock-18     [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  BatchNorm2D-51     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "     Conv2D-37       [[1, 192, 14, 14]]    [1, 192, 14, 14]       331,776    \n",
      "  BatchNorm2D-52     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "     Conv2D-38       [[1, 192, 14, 14]]    [1, 192, 14, 14]       36,864     \n",
      "  BatchNorm2D-53     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "      ReLU-19        [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  RepVGGBlock-19     [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  BatchNorm2D-54     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "     Conv2D-39       [[1, 192, 14, 14]]    [1, 192, 14, 14]       331,776    \n",
      "  BatchNorm2D-55     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "     Conv2D-40       [[1, 192, 14, 14]]    [1, 192, 14, 14]       36,864     \n",
      "  BatchNorm2D-56     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "      ReLU-20        [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  RepVGGBlock-20     [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  BatchNorm2D-57     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "     Conv2D-41       [[1, 192, 14, 14]]    [1, 192, 14, 14]       331,776    \n",
      "  BatchNorm2D-58     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "     Conv2D-42       [[1, 192, 14, 14]]    [1, 192, 14, 14]       36,864     \n",
      "  BatchNorm2D-59     [[1, 192, 14, 14]]    [1, 192, 14, 14]         768      \n",
      "      ReLU-21        [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  RepVGGBlock-21     [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "     Conv2D-43       [[1, 192, 14, 14]]    [1, 1280, 7, 7]       2,211,840   \n",
      "  BatchNorm2D-60     [[1, 1280, 7, 7]]     [1, 1280, 7, 7]         5,120     \n",
      "     Conv2D-44       [[1, 192, 14, 14]]    [1, 1280, 7, 7]        245,760    \n",
      "  BatchNorm2D-61     [[1, 1280, 7, 7]]     [1, 1280, 7, 7]         5,120     \n",
      "      ReLU-22        [[1, 1280, 7, 7]]     [1, 1280, 7, 7]           0       \n",
      "  RepVGGBlock-22     [[1, 192, 14, 14]]    [1, 1280, 7, 7]           0       \n",
      "AdaptiveAvgPool2D-1  [[1, 1280, 7, 7]]     [1, 1280, 1, 1]           0       \n",
      "     Linear-1           [[1, 1280]]            [1, 10]            12,810     \n",
      "===============================================================================\n",
      "Total params: 7,864,426\n",
      "Trainable params: 7,817,130\n",
      "Non-trainable params: 47,296\n",
      "-------------------------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 88.73\n",
      "Params size (MB): 30.00\n",
      "Estimated Total Size (MB): 119.30\n",
      "-------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_params': 7864426, 'trainable_params': 7817130}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 高层API\n",
    "model = paddle.Model(repvgg_a0)\n",
    "model.summary((1,3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#开始训练，也可以不训练，不影响后面运行，建议跳过这一部分\r\n",
    "model.prepare(optimizer=paddle.optimizer.Adam(learning_rate=0.001,parameters=model.parameters()),\r\n",
    "              loss=paddle.nn.CrossEntropyLoss(),\r\n",
    "              metrics=paddle.metric.Accuracy())\r\n",
    "\r\n",
    "vdl_callback = paddle.callbacks.VisualDL(log_dir='log') #训练可视化\r\n",
    "\r\n",
    "model.fit(\r\n",
    "    train_data=train_dataset, \r\n",
    "    eval_data=val_dataset, \r\n",
    "    batch_size=64, \r\n",
    "    epochs=10, \r\n",
    "    save_dir='save_models', \r\n",
    "    verbose=1, \r\n",
    "    callbacks=vdl_callback #训练可视化\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 基础API训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代器第一轮批次：\n",
      "图片数据 [128, 3, 224, 224]\n",
      "标签数据 [128]\n",
      "\n",
      "标签数据需要利用paddle.unsqueeze()变成[128,1]\n"
     ]
    }
   ],
   "source": [
    "train_batch = paddle.io.DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "val_batch = paddle.io.DataLoader(val_dataset, batch_size=128, shuffle=True , drop_last=True)\n",
    "\n",
    "for i in train_batch:\n",
    "    print('迭代器第一轮批次：')\n",
    "    print('图片数据',i[0].shape)\n",
    "    print('标签数据',i[1].shape)\n",
    "    break\n",
    "\n",
    "print('')\n",
    "print('标签数据需要利用paddle.unsqueeze()变成[128,1]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:648: UserWarning: When training, we now always track global mean and variance.\n",
      "  \"When training, we now always track global mean and variance.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch_id: 0, loss is: [2.377829], acc is: [0.1015625]\n",
      "epoch: 0, batch_id: 100, loss is: [1.6956916], acc is: [0.34375]\n",
      "epoch: 0, batch_id: 200, loss is: [1.2747836], acc is: [0.515625]\n",
      "epoch: 0, batch_id: 300, loss is: [1.0669378], acc is: [0.609375]\n",
      "batch_id: 0, loss is: [1.1263782], acc is: [0.609375]\n",
      "epoch: 1, batch_id: 0, loss is: [1.0189099], acc is: [0.5859375]\n",
      "epoch: 1, batch_id: 100, loss is: [0.98348755], acc is: [0.6640625]\n",
      "epoch: 1, batch_id: 200, loss is: [0.8737333], acc is: [0.6640625]\n",
      "epoch: 1, batch_id: 300, loss is: [0.9537698], acc is: [0.6796875]\n",
      "batch_id: 0, loss is: [0.6566773], acc is: [0.75]\n",
      "epoch: 2, batch_id: 0, loss is: [0.65497804], acc is: [0.8046875]\n",
      "epoch: 2, batch_id: 100, loss is: [0.501753], acc is: [0.8359375]\n",
      "epoch: 2, batch_id: 200, loss is: [0.6873904], acc is: [0.765625]\n",
      "epoch: 2, batch_id: 300, loss is: [0.7049354], acc is: [0.765625]\n",
      "batch_id: 0, loss is: [0.7807969], acc is: [0.734375]\n",
      "epoch: 3, batch_id: 0, loss is: [0.54755455], acc is: [0.828125]\n",
      "epoch: 3, batch_id: 100, loss is: [0.50581074], acc is: [0.859375]\n",
      "epoch: 3, batch_id: 200, loss is: [0.6492828], acc is: [0.7734375]\n",
      "epoch: 3, batch_id: 300, loss is: [0.4320676], acc is: [0.8515625]\n",
      "batch_id: 0, loss is: [0.7076975], acc is: [0.7421875]\n",
      "epoch: 4, batch_id: 0, loss is: [0.3518965], acc is: [0.875]\n",
      "epoch: 4, batch_id: 100, loss is: [0.37317213], acc is: [0.875]\n",
      "epoch: 4, batch_id: 200, loss is: [0.52790904], acc is: [0.8359375]\n",
      "epoch: 4, batch_id: 300, loss is: [0.35826653], acc is: [0.84375]\n",
      "batch_id: 0, loss is: [0.6337395], acc is: [0.7734375]\n",
      "epoch: 5, batch_id: 0, loss is: [0.38129145], acc is: [0.84375]\n",
      "epoch: 5, batch_id: 100, loss is: [0.25682098], acc is: [0.8984375]\n",
      "epoch: 5, batch_id: 200, loss is: [0.38154456], acc is: [0.8359375]\n",
      "epoch: 5, batch_id: 300, loss is: [0.25734812], acc is: [0.890625]\n",
      "batch_id: 0, loss is: [0.45733023], acc is: [0.8515625]\n",
      "epoch: 6, batch_id: 0, loss is: [0.2598531], acc is: [0.8828125]\n",
      "epoch: 6, batch_id: 100, loss is: [0.26805323], acc is: [0.90625]\n",
      "epoch: 6, batch_id: 200, loss is: [0.32644916], acc is: [0.875]\n",
      "epoch: 6, batch_id: 300, loss is: [0.28311527], acc is: [0.921875]\n",
      "batch_id: 0, loss is: [0.61987674], acc is: [0.828125]\n",
      "epoch: 7, batch_id: 0, loss is: [0.2908793], acc is: [0.90625]\n",
      "epoch: 7, batch_id: 100, loss is: [0.28610078], acc is: [0.90625]\n",
      "epoch: 7, batch_id: 200, loss is: [0.14960657], acc is: [0.953125]\n",
      "epoch: 7, batch_id: 300, loss is: [0.08674078], acc is: [0.96875]\n",
      "batch_id: 0, loss is: [0.69591975], acc is: [0.796875]\n",
      "epoch: 8, batch_id: 0, loss is: [0.14409035], acc is: [0.953125]\n",
      "epoch: 8, batch_id: 100, loss is: [0.1729168], acc is: [0.9375]\n",
      "epoch: 8, batch_id: 200, loss is: [0.24014926], acc is: [0.90625]\n",
      "epoch: 8, batch_id: 300, loss is: [0.10751949], acc is: [0.96875]\n",
      "batch_id: 0, loss is: [0.5920343], acc is: [0.8203125]\n",
      "epoch: 9, batch_id: 0, loss is: [0.06296505], acc is: [0.9921875]\n",
      "epoch: 9, batch_id: 100, loss is: [0.08444205], acc is: [0.9609375]\n",
      "epoch: 9, batch_id: 200, loss is: [0.18563382], acc is: [0.9296875]\n",
      "epoch: 9, batch_id: 300, loss is: [0.15956914], acc is: [0.9609375]\n",
      "batch_id: 0, loss is: [0.33377635], acc is: [0.875]\n"
     ]
    }
   ],
   "source": [
    "def fit(model,train_batch,val_batch,epoch):\n",
    "\n",
    "    #参数optimizer设置优化器，参数loss损失函数\n",
    "    opt = paddle.optimizer.Adam(learning_rate=0.001,parameters=model.parameters())\n",
    "    #参数loss损失函数\n",
    "    loss_fn = paddle.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    for epoch_id in range(epoch):\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for batch_id,batch_data in enumerate(train_batch):\n",
    "\n",
    "            input_batch = batch_data[0]\n",
    "            label_batch = paddle.unsqueeze(batch_data[1],axis=1)#标签维度变化\n",
    "\n",
    "            predict = model(input_batch)\n",
    "\n",
    "            loss = loss_fn(predict, label_batch)\n",
    "            acc = paddle.metric.accuracy(predict, label_batch)\n",
    "\n",
    "            #反向传播\n",
    "            loss.backward()   \n",
    "            #更新参数\n",
    "            opt.step()\n",
    "            #梯度清零\n",
    "            opt.clear_grad()\n",
    "\n",
    "            if batch_id % 100 == 0:\n",
    "                print(\"epoch: {}, batch_id: {}, loss is: {}, acc is: {}\".format(epoch_id, batch_id, loss.numpy(), acc.numpy()))\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        for batch_id,batch_data in enumerate(val_batch):\n",
    "\n",
    "            img_batch = batch_data[0]\n",
    "            label_batch = paddle.unsqueeze(batch_data[1],axis=1)\n",
    "\n",
    "            predict = model(img_batch)\n",
    "\n",
    "            loss = loss_fn(predict, label_batch)\n",
    "            acc = paddle.metric.accuracy(predict, label_batch)\n",
    "\n",
    "            if batch_id % 20 == 0:\n",
    "                print(\"batch_id: {}, loss is: {}, acc is: {}\".format(batch_id, loss.numpy(), acc.numpy()))\n",
    "\n",
    "fit(repvgg_a0, train_batch, val_batch, epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#模型转换\n",
    "def repvgg_model_convert(model, build_func):\n",
    "    converted_weights = {}#将训练模型各层权重bias存入字典\n",
    "    for name, module in model.named_sublayers():\n",
    "        if hasattr(module, 'repvgg_convert'):\n",
    "            kernel, bias = module.repvgg_convert()\n",
    "            converted_weights[name + '.rbr_reparam.weight'] = kernel\n",
    "            converted_weights[name + '.rbr_reparam.bias'] = bias\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            converted_weights[name + '.weight'] = module.weight.numpy()\n",
    "            converted_weights[name + '.bias'] = module.bias.numpy()\n",
    "\n",
    "    deploy_model = build_func\n",
    "    for name, param in deploy_model.named_parameters():\n",
    "        print('deploy param: ', name, np.mean(converted_weights[name]))\n",
    "        param.data = paddle.to_tensor(converted_weights[name])\n",
    "\n",
    "    return deploy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deploy param:  stage0.rbr_reparam.weight -0.012085067\n",
      "deploy param:  stage0.rbr_reparam.bias 0.045714345\n",
      "deploy param:  stage1.0.rbr_reparam.weight -4.6854173e-05\n",
      "deploy param:  stage1.0.rbr_reparam.bias -0.020605326\n",
      "deploy param:  stage1.1.rbr_reparam.weight 0.0008855257\n",
      "deploy param:  stage1.1.rbr_reparam.bias -0.12333813\n",
      "deploy param:  stage2.0.rbr_reparam.weight -0.00063567486\n",
      "deploy param:  stage2.0.rbr_reparam.bias 0.23614872\n",
      "deploy param:  stage2.1.rbr_reparam.weight -0.00056437775\n",
      "deploy param:  stage2.1.rbr_reparam.bias 0.24321677\n",
      "deploy param:  stage2.2.rbr_reparam.weight -0.00067081465\n",
      "deploy param:  stage2.2.rbr_reparam.bias 0.2832947\n",
      "deploy param:  stage2.3.rbr_reparam.weight -0.0004131663\n",
      "deploy param:  stage2.3.rbr_reparam.bias 0.04254788\n",
      "deploy param:  stage3.0.rbr_reparam.weight -0.0011545079\n",
      "deploy param:  stage3.0.rbr_reparam.bias 0.5689105\n",
      "deploy param:  stage3.1.rbr_reparam.weight -0.00042346717\n",
      "deploy param:  stage3.1.rbr_reparam.bias 0.020992994\n",
      "deploy param:  stage3.2.rbr_reparam.weight -0.00041332928\n",
      "deploy param:  stage3.2.rbr_reparam.bias 0.03356257\n",
      "deploy param:  stage3.3.rbr_reparam.weight -0.00028026314\n",
      "deploy param:  stage3.3.rbr_reparam.bias -0.103242874\n",
      "deploy param:  stage3.4.rbr_reparam.weight -0.00030400493\n",
      "deploy param:  stage3.4.rbr_reparam.bias -0.0461667\n",
      "deploy param:  stage3.5.rbr_reparam.weight -4.5831683e-05\n",
      "deploy param:  stage3.5.rbr_reparam.bias -0.26605505\n",
      "deploy param:  stage3.6.rbr_reparam.weight 6.658539e-05\n",
      "deploy param:  stage3.6.rbr_reparam.bias -0.32315442\n",
      "deploy param:  stage3.7.rbr_reparam.weight 9.768512e-05\n",
      "deploy param:  stage3.7.rbr_reparam.bias -0.32622793\n",
      "deploy param:  stage3.8.rbr_reparam.weight 0.000116009425\n",
      "deploy param:  stage3.8.rbr_reparam.bias -0.2892122\n",
      "deploy param:  stage3.9.rbr_reparam.weight 0.00022997792\n",
      "deploy param:  stage3.9.rbr_reparam.bias -0.36509892\n",
      "deploy param:  stage3.10.rbr_reparam.weight 0.00022792583\n",
      "deploy param:  stage3.10.rbr_reparam.bias -0.35063317\n",
      "deploy param:  stage3.11.rbr_reparam.weight 0.00033351785\n",
      "deploy param:  stage3.11.rbr_reparam.bias -0.3873196\n",
      "deploy param:  stage3.12.rbr_reparam.weight 0.0002637774\n",
      "deploy param:  stage3.12.rbr_reparam.bias -0.32720482\n",
      "deploy param:  stage3.13.rbr_reparam.weight 4.850667e-05\n",
      "deploy param:  stage3.13.rbr_reparam.bias -0.097426474\n",
      "deploy param:  stage4.0.rbr_reparam.weight 7.6041026e-05\n",
      "deploy param:  stage4.0.rbr_reparam.bias -0.17974474\n",
      "deploy param:  linear.weight -0.0033639586\n",
      "deploy param:  linear.bias 2.7480442e-05\n"
     ]
    }
   ],
   "source": [
    "deploy_model = repvgg_model_convert(repvgg_a0, create_RepVGG_A0(deploy=True,num_classes=10))\n",
    "#输出每一block参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id: 0, loss is: [0.66172945], acc is: [0.765625]\n",
      "batch_id: 20, loss is: [1.0397379], acc is: [0.7890625]\n",
      "batch_id: 40, loss is: [0.89671266], acc is: [0.7890625]\n",
      "batch_id: 60, loss is: [0.49206328], acc is: [0.84375]\n"
     ]
    }
   ],
   "source": [
    "# 模型推理\n",
    "deploy_model.eval()\n",
    "\n",
    "loss_fn = paddle.nn.CrossEntropyLoss()\n",
    "\n",
    "for batch_id,batch_data in enumerate(val_batch):\n",
    "\n",
    "    img_batch = batch_data[0]\n",
    "    label_batch = paddle.unsqueeze(batch_data[1],axis=1)\n",
    "\n",
    "    predict = repvgg_a0(img_batch)\n",
    "\n",
    "    loss = loss_fn(predict, label_batch)\n",
    "    acc = paddle.metric.accuracy(predict, label_batch)\n",
    "\n",
    "    if batch_id % 20 == 0:\n",
    "        print(\"batch_id: {}, loss is: {}, acc is: {}\".format(batch_id, loss.numpy(), acc.numpy()))\n",
    "\n",
    "#和上面训练模型比一下acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "   Layer (type)         Input Shape          Output Shape         Param #    \n",
      "===============================================================================\n",
      "     Conv2D-45       [[1, 3, 224, 224]]   [1, 48, 112, 112]        1,344     \n",
      "      ReLU-23       [[1, 48, 112, 112]]   [1, 48, 112, 112]          0       \n",
      "  RepVGGBlock-23     [[1, 3, 224, 224]]   [1, 48, 112, 112]          0       \n",
      "     Conv2D-46      [[1, 48, 112, 112]]    [1, 48, 56, 56]        20,784     \n",
      "      ReLU-24        [[1, 48, 56, 56]]     [1, 48, 56, 56]           0       \n",
      "  RepVGGBlock-24    [[1, 48, 112, 112]]    [1, 48, 56, 56]           0       \n",
      "     Conv2D-47       [[1, 48, 56, 56]]     [1, 48, 56, 56]        20,784     \n",
      "      ReLU-25        [[1, 48, 56, 56]]     [1, 48, 56, 56]           0       \n",
      "  RepVGGBlock-25     [[1, 48, 56, 56]]     [1, 48, 56, 56]           0       \n",
      "     Conv2D-48       [[1, 48, 56, 56]]     [1, 96, 28, 28]        41,568     \n",
      "      ReLU-26        [[1, 96, 28, 28]]     [1, 96, 28, 28]           0       \n",
      "  RepVGGBlock-26     [[1, 48, 56, 56]]     [1, 96, 28, 28]           0       \n",
      "     Conv2D-49       [[1, 96, 28, 28]]     [1, 96, 28, 28]        83,040     \n",
      "      ReLU-27        [[1, 96, 28, 28]]     [1, 96, 28, 28]           0       \n",
      "  RepVGGBlock-27     [[1, 96, 28, 28]]     [1, 96, 28, 28]           0       \n",
      "     Conv2D-50       [[1, 96, 28, 28]]     [1, 96, 28, 28]        83,040     \n",
      "      ReLU-28        [[1, 96, 28, 28]]     [1, 96, 28, 28]           0       \n",
      "  RepVGGBlock-28     [[1, 96, 28, 28]]     [1, 96, 28, 28]           0       \n",
      "     Conv2D-51       [[1, 96, 28, 28]]     [1, 96, 28, 28]        83,040     \n",
      "      ReLU-29        [[1, 96, 28, 28]]     [1, 96, 28, 28]           0       \n",
      "  RepVGGBlock-29     [[1, 96, 28, 28]]     [1, 96, 28, 28]           0       \n",
      "     Conv2D-52       [[1, 96, 28, 28]]     [1, 192, 14, 14]       166,080    \n",
      "      ReLU-30        [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  RepVGGBlock-30     [[1, 96, 28, 28]]     [1, 192, 14, 14]          0       \n",
      "     Conv2D-53       [[1, 192, 14, 14]]    [1, 192, 14, 14]       331,968    \n",
      "      ReLU-31        [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  RepVGGBlock-31     [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "     Conv2D-54       [[1, 192, 14, 14]]    [1, 192, 14, 14]       331,968    \n",
      "      ReLU-32        [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  RepVGGBlock-32     [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "     Conv2D-55       [[1, 192, 14, 14]]    [1, 192, 14, 14]       331,968    \n",
      "      ReLU-33        [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  RepVGGBlock-33     [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "     Conv2D-56       [[1, 192, 14, 14]]    [1, 192, 14, 14]       331,968    \n",
      "      ReLU-34        [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  RepVGGBlock-34     [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "     Conv2D-57       [[1, 192, 14, 14]]    [1, 192, 14, 14]       331,968    \n",
      "      ReLU-35        [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  RepVGGBlock-35     [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "     Conv2D-58       [[1, 192, 14, 14]]    [1, 192, 14, 14]       331,968    \n",
      "      ReLU-36        [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  RepVGGBlock-36     [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "     Conv2D-59       [[1, 192, 14, 14]]    [1, 192, 14, 14]       331,968    \n",
      "      ReLU-37        [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  RepVGGBlock-37     [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "     Conv2D-60       [[1, 192, 14, 14]]    [1, 192, 14, 14]       331,968    \n",
      "      ReLU-38        [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  RepVGGBlock-38     [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "     Conv2D-61       [[1, 192, 14, 14]]    [1, 192, 14, 14]       331,968    \n",
      "      ReLU-39        [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  RepVGGBlock-39     [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "     Conv2D-62       [[1, 192, 14, 14]]    [1, 192, 14, 14]       331,968    \n",
      "      ReLU-40        [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  RepVGGBlock-40     [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "     Conv2D-63       [[1, 192, 14, 14]]    [1, 192, 14, 14]       331,968    \n",
      "      ReLU-41        [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  RepVGGBlock-41     [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "     Conv2D-64       [[1, 192, 14, 14]]    [1, 192, 14, 14]       331,968    \n",
      "      ReLU-42        [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  RepVGGBlock-42     [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "     Conv2D-65       [[1, 192, 14, 14]]    [1, 192, 14, 14]       331,968    \n",
      "      ReLU-43        [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "  RepVGGBlock-43     [[1, 192, 14, 14]]    [1, 192, 14, 14]          0       \n",
      "     Conv2D-66       [[1, 192, 14, 14]]    [1, 1280, 7, 7]       2,213,120   \n",
      "      ReLU-44        [[1, 1280, 7, 7]]     [1, 1280, 7, 7]           0       \n",
      "  RepVGGBlock-44     [[1, 192, 14, 14]]    [1, 1280, 7, 7]           0       \n",
      "AdaptiveAvgPool2D-2  [[1, 1280, 7, 7]]     [1, 1280, 1, 1]           0       \n",
      "     Linear-2           [[1, 1280]]            [1, 10]            12,810     \n",
      "===============================================================================\n",
      "Total params: 7,041,194\n",
      "Trainable params: 7,041,194\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 41.07\n",
      "Params size (MB): 26.86\n",
      "Estimated Total Size (MB): 68.50\n",
      "-------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_params': 7041194, 'trainable_params': 7041194}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看模型\n",
    "#print(deploy_model)\n",
    "\n",
    "#高阶封装查看\n",
    "deploy_model_hapi=paddle.Model(deploy_model)\n",
    "deploy_model_hapi.summary((1,3,224,224))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "和上面训练模型（高阶封装）对比一下大小，这个是不是很小呀，才68m，一路的3x3卷积是不是特别容易部署\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/31ccb2be06434018b146705b1b0b7b46f2f7876d8dac42b78f394088a32b5da9)\n",
    "\n",
    "现有的计算库比如CUDA对3x3运算支持有很大的优势，上图可以看出其计算密度（FLOPs/推理时间）达到了38.10!\n",
    "\n",
    "作者在结尾补充，在低端cpu设备，mobilenetv3还是有优势，但是在低端gpu设备下，repvgg优势还是很明显\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### deploy_model 可视化\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/fbc60174ae374f8c9967b897050a00ca072d870a1bd44c629a9ecaa0b24d058a)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
